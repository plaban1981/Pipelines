{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Auomate_ML_with_Pipeline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjhUUgy1C3Bd7MJWneshix",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plaban1981/Pipelines/blob/master/Auomate_ML_with_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqigVklM6Y2t",
        "colab_type": "text"
      },
      "source": [
        "# Automate the Machine Learning Model Implementation with Sklearn Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-edys9t26jAg",
        "colab_type": "text"
      },
      "source": [
        "Many times while working on Machine Learning problems, we come across the Machine Learning task where we want to preprocess our data and test our model with different classifiers to choose the best one. \n",
        "\n",
        "In such cases, fitting each classifier individually on training data and then testing the model is too tedious, not to mention there’s a large amount of redundant coding is also involved. \n",
        "\n",
        "Plus, if your algorithm involves cross-validation and your preprocessing step involves operation like normalization or standardization, performing normalization or standardization on the full training set before learning will influence your training set with the scale of the test set. Wouldn’t it be nice if there was a single solution to all these problems?\n",
        "\n",
        "Well, there’s! **Scikit-Learn has a Pipeline module** that provides an easy way to tackle the above problems.\n",
        "\n",
        "\n",
        "**Pipeline** is a function that sequentially applies a list of transforms and a final estimator. The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "Now let’s see an implementat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMrk9bad6UJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oplasReX9cEx",
        "colab_type": "text"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIefR4ZJ8Yxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "Y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kmbyHpY9e2J",
        "colab_type": "text"
      },
      "source": [
        "# split the data into training and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmb1eui68whc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.15,random_state=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKenNS3j9iTU",
        "colab_type": "text"
      },
      "source": [
        "# make a list of classifier names and their respective functions from Scikit-Learn. And finally, zip them together. This step will ensure that we pass all the classifiers to our Pipeline function in a single shot along with their names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WonfYXJo9ErC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier_names = [\"Logistic Regression\", \"KNN\", \"Random Forest\",\"SVM\"]\n",
        "classifiers = [LogisticRegression(), KNeighborsClassifier(), RandomForestClassifier(), LinearSVC()]\n",
        "zipped_clf = zip(classifier_names,classifiers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSxtF-bo9sbQ",
        "colab_type": "text"
      },
      "source": [
        "#Prepare Pipeline of Standardscalar with classifiers, and feed the result of Pipeline to fit_classifier() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4Y14QXE9t0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier(classifier,X_train, y_train, X_test, y_test):\n",
        "  result = []\n",
        "  for n,c in classifier:\n",
        "    print('Classifier : ',n)\n",
        "    print('*'*80)\n",
        "    checker_pipeline = Pipeline([('stndarize',StandardScaler()),\n",
        "                                 ('classifier',c) ])\n",
        "    print(\"Validation result for {}\".format(n))\n",
        "    print(c)\n",
        "    print('*'*80)\n",
        "    clf_acc = fit_classifier(checker_pipeline,X_train, y_train, X_test, y_test)\n",
        "    result.append((n,clf_acc))\n",
        "    \n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EJsF70v_mym",
        "colab_type": "text"
      },
      "source": [
        "# define fit_classifier() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaIwsMll_Z5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_classifier(pipeline, x_train, y_train, x_test, y_test):\n",
        "    model_fit = pipeline.fit(x_train, y_train)\n",
        "    y_pred = model_fit.predict(x_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW2D-6AA_rnI",
        "colab_type": "text"
      },
      "source": [
        "# Test the algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpQKd8Bx_vtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "9e792891-996a-45cc-ede9-530efeaedc33"
      },
      "source": [
        "result = classifier(zipped_clf, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier :  Logistic Regression\n",
            "********************************************************************************\n",
            "Validation result for Logistic Regression\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "********************************************************************************\n",
            "accuracy score: 100.00%\n",
            "Classifier :  KNN\n",
            "********************************************************************************\n",
            "Validation result for KNN\n",
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n",
            "********************************************************************************\n",
            "accuracy score: 95.65%\n",
            "Classifier :  Random Forest\n",
            "********************************************************************************\n",
            "Validation result for Random Forest\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "********************************************************************************\n",
            "accuracy score: 100.00%\n",
            "Classifier :  SVM\n",
            "********************************************************************************\n",
            "Validation result for SVM\n",
            "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "          verbose=0)\n",
            "********************************************************************************\n",
            "accuracy score: 95.65%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHsereP5A3jk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "08773951-2ace-4e33-8449-50d52959e4ca"
      },
      "source": [
        "result"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Logistic Regression', 1.0),\n",
              " ('KNN', 0.9565217391304348),\n",
              " ('Random Forest', 1.0),\n",
              " ('SVM', 0.9565217391304348)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNIMpPBkA4S6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}